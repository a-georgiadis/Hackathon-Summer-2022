{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Basic Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayazZs0_TGKT",
        "outputId": "6bacd656-79e4-42c9-d649-7b1b731aef6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Upload and Cleaning \n",
        "\n"
      ],
      "metadata": {
        "id": "9q-QT8ebVg2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssg-WLGqSFds"
      },
      "outputs": [],
      "source": [
        "# Upload training data \n",
        "train_features = pd.read_csv('features_train.tsv', sep = '\\t')\n",
        "train_labels = train_features.pop('DIFF')\n",
        "BC_train = pd.read_csv('tfbs_score_BC217_train.tsv', sep = '\\t')\n",
        "YJ_train = pd.read_csv('tfbs_score_YJF153_train.tsv', sep = '\\t' )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload testing data\n",
        "test_features = pd.read_csv('features_test.tsv', sep = '\\t')\n",
        "BC_test = pd.read_csv('tfbs_score_BC217_test.tsv', sep = '\\t')\n",
        "YJ_test = pd.read_csv('tfbs_score_YJF153_test.tsv', sep = '\\t' )"
      ],
      "metadata": {
        "id": "P_KDKAHXFepD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at some info \n",
        "for column in train_features.columns :\n",
        "  unique_values = train_features[column].unique()\n",
        "  length = len(unique_values)\n",
        "\n",
        "  if length < 20: \n",
        "    print(column + ' : ', unique_values , '\\n')\n",
        "  else:\n",
        "    print(column + ' : ', length , '\\n')\n"
      ],
      "metadata": {
        "id": "_naU_yp--Yjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean the _features dataframes\n",
        "def clean_features(df):\n",
        "  # Drop columns with non relevant or little info\n",
        "  df.drop('type', axis =1 , inplace = True) \n",
        "  df.drop('gene', axis =1 , inplace = True)\n",
        "  df.drop(['len_intron','pos_intron','len_5UTRintron', 'pos_5UTRintron'], axis =1 , inplace = True)\n",
        "\n",
        "  # Map chromosome numbers to numbers\n",
        "  df['chromosome'] = df['chromosome'].map({'chr1':1,  'chr2':2, 'chr3':3, 'chr4':4, 'chr5':5, \n",
        "                                  'chr6':6, 'chr7':7, 'chr8':8, 'chr9':9,  'chr10':10,\n",
        "                                  'chr11':11, 'chr12':12, 'chr13':13, 'chr14':14,\n",
        "                                  'chr15':15, 'chr16':16 })\n",
        "  return df \n"
      ],
      "metadata": {
        "id": "mVl3WxryquDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean dataframes\n",
        "train_features = clean_features(train_features)\n",
        "\n",
        "# Also drop diff for test data since it contains no info\n",
        "test_features.drop('DIFF', axis = 1, inplace=True)\n",
        "test_features = clean_features(test_features)"
      ],
      "metadata": {
        "id": "pmmXx5iOA6V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode non numerical data"
      ],
      "metadata": {
        "id": "S128Oq5MuiVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure out some info about the genotype data \n",
        "genotype_data = ['YJF153_geno_SNP_promoter', 'BC217_geno_SNP_promoter',\n",
        "                 'YJF153_geno_MIXED_promoter','BC217_geno_MIXED_promoter',\n",
        "                 'YJF153_geno_SNP_3end','BC217_geno_SNP_3end','YJF153_geno_MIXED_3end',\n",
        "                 'BC217_geno_MIXED_3end', 'YJF153_geno_SNPs_gene','BC217_geno_SNPs_gene',\n",
        "                 'YJF153_geno_MIXED_gene','BC217_geno_MIXED_gene']\n",
        "\n",
        "largest = 0\n",
        "running_total = 0 \n",
        "running_num = 0 \n",
        "\n",
        "for column in genotype_data:\n",
        "  for i in range(train_features.shape[0]):\n",
        "    try:\n",
        "      current = len(train_features[column][i].split(':'))\n",
        "      running_total = running_total + current \n",
        "      running_num =  running_num + 1\n",
        "    except: continue\n",
        "    if (largest == 0) | (current > largest) :\n",
        "      largest = current\n",
        "    \n",
        "print('largest:' , largest)\n",
        "print('total:', running_total, 'num:',running_num)\n",
        "print('avg:' ,running_total/running_num)"
      ],
      "metadata": {
        "id": "Dk6ZEdhGWqXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52829013-9e3a-4ea6-e84b-682340d96a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largest: 277\n",
            "total: 94818 num: 16824\n",
            "avg: 5.635877318116976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative Functions required for translating with new method\n",
        "def checkIfNewChunk(existingChunks, chunk):\n",
        "    if chunk in existingChunks:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def extractSequenceChunks(train_features, genotype_data):\n",
        "    unique_seq_chunks = ['A','T','C','G']\n",
        "    for column in genotype_data:\n",
        "        for i in range(train_features.shape[0]):\n",
        "            try:\n",
        "                getChunks = train_features[column][i].split(\":\")\n",
        "                for chunk in getChunks:\n",
        "                    newChunk = checkIfNewChunk(unique_seq_chunks, chunk)\n",
        "                    if newChunk:\n",
        "                        unique_seq_chunks.append(chunk)\n",
        "            except: continue\n",
        "    np.save('uniqueSeqChunks', unique_seq_chunks)\n",
        "    print('numUniqueSeq:', len(unique_seq_chunks))\n",
        "\n",
        "def encodeGenotypes(value, uniqueSeqChunks):\n",
        "  try:\n",
        "      return uniqueSeqChunks.index(value)\n",
        "  except:\n",
        "      return len(uniqueSeqChunks)\n",
        "\n",
        "def translateColumnChunks(train_features, genotype_data, uniqueSeqChunks ,cutoffSize=20):\n",
        "    rows = train_features.shape[0]\n",
        "    # Go through each column\n",
        "    for column in genotype_data:\n",
        "        # Allocate space for each translation of 20\n",
        "        translatedColumn = np.zeros((rows, cutoffSize))\n",
        "        for i in range(rows):\n",
        "            if type(train_features[column][i]) != str:\n",
        "                getChunks = [0]\n",
        "            else:\n",
        "                getChunks = train_features[column][i].split(\":\")\n",
        "            for j in range(cutoffSize):\n",
        "                try:\n",
        "                    translatedColumn[i][j] = encodeGenotypes(getChunks[j], uniqueSeqChunks)+1\n",
        "                except:\n",
        "                    translatedColumn[i][j] = 0\n",
        "        train_features.drop(columns=column, inplace=True)\n",
        "        for i in range(cutoffSize):\n",
        "            columnAdding = column + \"_SplitPart_\" + str(i)\n",
        "            train_features[columnAdding] = translatedColumn[:,i].tolist()\n",
        "    return train_features\n",
        "\n",
        "# Method for translating the numeric input\n",
        "def translateDistChunks(train_features, numerical_lists, cutoffSize=20):\n",
        "    rows = train_features.shape[0]\n",
        "    # Go through each column\n",
        "    for column in numerical_lists:\n",
        "        # Allocate space for each translation of 20\n",
        "        translatedColumn = np.zeros((rows, cutoffSize), dtype=np.float32)\n",
        "        for i in range(rows):\n",
        "            if type(train_features[column][i]) != str:\n",
        "                getChunks = [0]\n",
        "            else:\n",
        "                getChunks = train_features[column][i].split(\":\")\n",
        "            for j in range(cutoffSize):\n",
        "                try:\n",
        "                    translatedColumn[i][j] = np.float32(getChunks[j])\n",
        "                except:\n",
        "                    translatedColumn[i][j] = 0\n",
        "        train_features.drop(columns=column, inplace=True)\n",
        "        for i in range(cutoffSize):\n",
        "            columnAdding = column + \"_SplitPart_\" + str(i)\n",
        "            train_features[columnAdding] = translatedColumn[:,i].tolist()\n",
        "    return train_features\n",
        "\n",
        "# Requirements\n",
        "genotype_data = ['YJF153_geno_SNP_promoter', 'BC217_geno_SNP_promoter',\n",
        "                 'YJF153_geno_MIXED_promoter','BC217_geno_MIXED_promoter',\n",
        "                 'YJF153_geno_SNP_3end','BC217_geno_SNP_3end','YJF153_geno_MIXED_3end',\n",
        "                 'BC217_geno_MIXED_3end', 'YJF153_geno_SNPs_gene','BC217_geno_SNPs_gene',\n",
        "                 'YJF153_geno_MIXED_gene','BC217_geno_MIXED_gene']\n",
        "numerical_lists = ['dist_SNP_promoter', 'dist_MIXED_promoter','dist_SNPs_gene', 'dist_MIXED_gene']\n",
        "\n",
        "# Code to execute\n",
        "extractSequenceChunks(train_features,genotype_data)\n",
        "uniqueSeqChunks = np.load(\"uniqueSeqChunks.npy\")\n",
        "\n",
        "train_features_translated = translateColumnChunks(train_features, genotype_data, uniqueSeqChunks)\n",
        "train_features_translate = translateDistChunks(train_features_translated, numerical_lists)\n",
        "\n",
        "test_features_translated = translateColumnChunks(test_features, genotype_data, uniqueSeqChunks)\n",
        "test_features_translate = translateDistChunks(test_features_translated, numerical_lists)"
      ],
      "metadata": {
        "id": "qifFfhapI5-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9306a1-a3c3-4c54-e689-c6f3ab82c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numUniqueSeq: 866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we don't need to change variable names later\n",
        "train_features = train_features_translate.copy()\n",
        "test_features = test_features_translate.copy()"
      ],
      "metadata": {
        "id": "soArl2MqjRdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode ACTG values in genotype data\n",
        "def amino_to_num(string): \n",
        "  if type(string) == int:\n",
        "    return string\n",
        "\n",
        "  try:\n",
        "    letters = string.split(':')\n",
        "  except: \n",
        "    letters = ''\n",
        "\n",
        "  letter_vocab = {'A': 1, 'T': 2, 'C': 3, 'G':4}\n",
        "  numbers = ''\n",
        "\n",
        "  # Encode \n",
        "  for letter in letters:\n",
        "    if len(letter) == 1:\n",
        "      number = str(letter_vocab[letter])\n",
        "      numbers = numbers + number \n",
        "    elif len(letter) > 1:\n",
        "      for char in letter:\n",
        "       number = str(letter_vocab[char])\n",
        "       numbers = numbers + number \n",
        "    numbers = numbers + '5'\n",
        "\n",
        "  # Pad to 50 characters \n",
        "  num_to_pad = 50 - len(numbers)\n",
        "  if num_to_pad >= 0:\n",
        "    numbers = numbers + '0' * num_to_pad\n",
        "  elif num_to_pad < 0:\n",
        "    numbers = numbers[0:50]\n",
        "\n",
        "  # Convert to integer\n",
        "  numbers = int(numbers)\n",
        "\n",
        "  return numbers\n"
      ],
      "metadata": {
        "id": "giqpIKbvV9kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the genotype data in training and testing dataframes \n",
        "#for column in genotype_data:\n",
        "  #train_features[column]=train_features[column].map(amino_to_num)\n",
        "  #test_features[column]=test_features[column].map(amino_to_num)"
      ],
      "metadata": {
        "id": "BLgJvpiHeeBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More data cleaning..."
      ],
      "metadata": {
        "id": "7ljMYSpabS16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get rid of colons in distance lists \n",
        "numerical_lists = ['dist_SNP_promoter', 'dist_MIXED_promoter','dist_SNPs_gene', 'dist_MIXED_gene']"
      ],
      "metadata": {
        "id": "uZEjBDV5HO-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_colons(string):\n",
        "   if type(string) != str:\n",
        "    return string\n",
        "\n",
        "   try:\n",
        "      letters = string.split(':')\n",
        "   except: \n",
        "     letters = ''\n",
        "  \n",
        "   list_nums = ''\n",
        "   numbers=string.split(':')\n",
        "   for number in numbers[0:50]:\n",
        "      list_nums = list_nums + number\n",
        "   \n",
        "   num=int(list_nums)\n",
        "\n",
        "   return num\n",
        "\n"
      ],
      "metadata": {
        "id": "jHcM4bApHg9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of colons in distance lists\n",
        "#for column in numerical_lists:\n",
        "  #train_features[column]=train_features[column].map(remove_colons)\n",
        "  #test_features[column] = train_features[column].map(remove_colons)"
      ],
      "metadata": {
        "id": "-YFRcI_fES00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the column with dashed values and adds them to the dataSet at the end could make this more robust for scenario of n_exons but did this to starts\n",
        "train_features[[\"pos_exon1_start\", \"pos_exon1_end\", \"pos_exon2_start\", \"pos_exon2_end\", \"pos_exon3_start\", \"pos_exon3_end\"]] = train_features[\"pos_exon\"].str.split(r'\\W', expand = True)\n",
        "train_features.drop(columns='pos_exon', inplace=True)\n",
        "\n",
        "# Replace all Nan and Na values with 0\n",
        "train_features.fillna(0, inplace=True)\n",
        "\n",
        "# Convert all columns that are possible into floats and print to screen a list where not possible\n",
        "failFloat32 = []\n",
        "for column in train_features.columns:\n",
        "    try: \n",
        "        train_features[column]=train_features[column].astype(np.float64)\n",
        "    except:\n",
        "        failFloat32.append(column)\n",
        "        \n",
        "print(failFloat32)\n",
        "  "
      ],
      "metadata": {
        "id": "36Lxq6Dd33S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d130aa26-8d2f-48ba-f835-df44dae1df6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SGD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the column with dashed values and adds them to the dataSet at the end could make this more robust for scenario of n_exons but did this to starts\n",
        "splitColumns = test_features[\"pos_exon\"].str.split(r'\\W', expand = True)\n",
        "try:\n",
        "  test_features[[\"pos_exon1_start\", \"pos_exon1_end\", \"pos_exon2_start\", \"pos_exon2_end\", \"pos_exon3_start\", \"pos_exon3_end\"]] = splitColumns\n",
        "except:\n",
        "  columns = [\"pos_exon1_start\", \"pos_exon1_end\", \"pos_exon2_start\", \"pos_exon2_end\", \"pos_exon3_start\", \"pos_exon3_end\"]\n",
        "  numRows, numColumns = splitColumns.shape\n",
        "  # Grab the max range\n",
        "  for i in range(6):\n",
        "    if i < numColumns:\n",
        "      columnToAdd = splitColumns.iloc[:,i]\n",
        "    else:\n",
        "      columnToAdd = np.zeros((numRows,1))\n",
        "    test_features[columns[i]]= columnToAdd\n",
        "    \n",
        "\n",
        "test_features.drop(columns='pos_exon', inplace=True)\n",
        "\n",
        "# Replace all Nan and Na values with 0\n",
        "test_features.fillna(0, inplace=True)\n",
        "\n",
        "# Convert all columns that are possible into floats and print to screen a list where not possible\n",
        "failFloat32 = []\n",
        "for column in test_features.columns:\n",
        "  try: \n",
        "        test_features[column]=test_features[column].astype(np.float64)\n",
        "  except:\n",
        "        failFloat32.append(column)\n",
        "        \n",
        "print(failFloat32)"
      ],
      "metadata": {
        "id": "Mr-2DHYPRNyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa52ef7-990c-4860-f26f-9753ee90651b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SGD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize numerical columns up to this point"
      ],
      "metadata": {
        "id": "0dJ73eSTcO9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "train_SGD = train_features.pop('SGD')\n",
        "test_SGD = test_features.pop('SGD')\n",
        "train_features=(train_features-train_features.min())/(train_features.max()-train_features.min())\n",
        "test_features= (test_features-test_features.min())/(test_features.max()-test_features.min())\n",
        "\n",
        "train_features['SGD']=train_SGD\n",
        "test_features['SGD']=test_SGD"
      ],
      "metadata": {
        "id": "CrzxUJ-mYiqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join features dataframe with TFBS dataframes"
      ],
      "metadata": {
        "id": "5_gb9gX3oIfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare the TFBS data \n",
        "def prepare_TFBS_data(df):\n",
        "    df.rename({'gene':'SGD'},axis=1, inplace=True)\n",
        "    df.drop(df.columns[1], axis =1 , inplace = True)\n",
        "    df.set_index('SGD', inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "HV2jOL29nVKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare TFBS data\n",
        "# Training\n",
        "YJ_train = prepare_TFBS_data(YJ_train)\n",
        "BC_train = prepare_TFBS_data(BC_train)\n",
        "TFBS_train = abs(YJ_train-BC_train)\n",
        "\n",
        "# Testing\n",
        "YJ_test = prepare_TFBS_data(YJ_test)\n",
        "BC_test = prepare_TFBS_data(BC_test)\n",
        "TFBS_test = abs(YJ_test-BC_test)\n"
      ],
      "metadata": {
        "id": "HMMIhMZ1kga_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join Data \n",
        "# Training\n",
        "train_features = train_features.join(TFBS_train, on='SGD')\n",
        "\n",
        "# Testing \n",
        "test_features = test_features.join(TFBS_test, on='SGD')"
      ],
      "metadata": {
        "id": "wcBq1Wd4kjCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make copies so up to now is preserved \n",
        "training_features = train_features.copy()\n",
        "testing_features = test_features.copy()\n",
        "\n",
        "# Get rid of SGD for training data \n",
        "training_features.fillna(0, inplace=True)\n",
        "training_features.drop('SGD', axis = 1, inplace=True)\n",
        "\n",
        "# Pop SGD gene identifier for testing data \n",
        "testing_features.fillna(0, inplace=True)\n",
        "test_SGD = testing_features.pop('SGD')\n"
      ],
      "metadata": {
        "id": "n0PgPsz3w0Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in testing_features.columns:\n",
        "  if testing_features[column].isnull().any()==True:\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "NajX0vI1MOm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTES FROM DIANA 8/24 WORK\n",
        "\n",
        "After using a difference between the TFBS data rather than each table separately, it seems that the # epochs can be increased (to 100 at least) without causing the convergence on a value we were seeing before. So thats good :)"
      ],
      "metadata": {
        "id": "K32JwmlZI_eX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Notes:\n",
        "\n",
        "- We could potentially encode the genotype SNPs using a one-hot encoding - https://www.nature.com/articles/s41467-020-19921-4\n",
        "\n",
        "- Does standardising the strand type make sense: AKA writing a script to convert all to strand 0 or all to strand 1. Since they are just inverse of one another\n",
        "\n",
        "- Data in TFBS seems to be structured where each group of 3 columns is one feature with data score,position and strand: Information on the TFBS, https://pubmed.ncbi.nlm.nih.gov/12176838/\n"
      ],
      "metadata": {
        "id": "Bz3uSxckroVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model "
      ],
      "metadata": {
        "id": "B_X2dY14VaY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for training\n",
        "epochs = 100\n",
        "batch_size = 15 \n",
        "validation_split = 0.2 \n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "eqNpc1fcsZZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General Model Framework\n",
        "# Create Model\n",
        "model= tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(64, activation = 'relu', input_shape=(training_features.shape[1],)))\n",
        "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile Model \n",
        "model.compile(optimizer='adam', loss= 'mean_squared_error' ,metrics= 'mse')"
      ],
      "metadata": {
        "id": "-T9Nwn29ruv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "model.fit(training_features, train_labels, epochs = epochs, batch_size = batch_size, validation_split= validation_split)"
      ],
      "metadata": {
        "id": "KIftfDFEsHeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e50588c-6660-4ce7-82c7-62da3f379f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "149/149 [==============================] - 2s 10ms/step - loss: 0.6022 - mse: 0.6022 - val_loss: 0.4750 - val_mse: 0.4750\n",
            "Epoch 2/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5504 - mse: 0.5504 - val_loss: 0.4432 - val_mse: 0.4432\n",
            "Epoch 3/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5317 - mse: 0.5317 - val_loss: 0.4459 - val_mse: 0.4459\n",
            "Epoch 4/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5267 - mse: 0.5267 - val_loss: 0.4565 - val_mse: 0.4565\n",
            "Epoch 5/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.5283 - mse: 0.5283 - val_loss: 0.4406 - val_mse: 0.4406\n",
            "Epoch 6/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.5191 - mse: 0.5191 - val_loss: 0.4669 - val_mse: 0.4669\n",
            "Epoch 7/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5172 - mse: 0.5172 - val_loss: 0.4550 - val_mse: 0.4550\n",
            "Epoch 8/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5127 - mse: 0.5127 - val_loss: 0.4754 - val_mse: 0.4754\n",
            "Epoch 9/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5136 - mse: 0.5136 - val_loss: 0.4579 - val_mse: 0.4579\n",
            "Epoch 10/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5123 - mse: 0.5123 - val_loss: 0.4612 - val_mse: 0.4612\n",
            "Epoch 11/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5064 - mse: 0.5064 - val_loss: 0.4630 - val_mse: 0.4630\n",
            "Epoch 12/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5126 - mse: 0.5126 - val_loss: 0.4539 - val_mse: 0.4539\n",
            "Epoch 13/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5000 - mse: 0.5000 - val_loss: 0.4837 - val_mse: 0.4837\n",
            "Epoch 14/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5050 - mse: 0.5050 - val_loss: 0.4627 - val_mse: 0.4627\n",
            "Epoch 15/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4932 - mse: 0.4932 - val_loss: 0.5013 - val_mse: 0.5013\n",
            "Epoch 16/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4877 - mse: 0.4877 - val_loss: 0.4922 - val_mse: 0.4922\n",
            "Epoch 17/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4767 - mse: 0.4767 - val_loss: 0.4851 - val_mse: 0.4851\n",
            "Epoch 18/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4859 - mse: 0.4859 - val_loss: 0.5122 - val_mse: 0.5122\n",
            "Epoch 19/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4639 - mse: 0.4639 - val_loss: 0.4954 - val_mse: 0.4954\n",
            "Epoch 20/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4617 - mse: 0.4617 - val_loss: 0.5073 - val_mse: 0.5073\n",
            "Epoch 21/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4560 - mse: 0.4560 - val_loss: 0.5217 - val_mse: 0.5217\n",
            "Epoch 22/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.4521 - mse: 0.4521 - val_loss: 0.4891 - val_mse: 0.4891\n",
            "Epoch 23/100\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.4531 - mse: 0.4531 - val_loss: 0.5557 - val_mse: 0.5557\n",
            "Epoch 24/100\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.4348 - mse: 0.4348 - val_loss: 0.5173 - val_mse: 0.5173\n",
            "Epoch 25/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4292 - mse: 0.4292 - val_loss: 0.4751 - val_mse: 0.4751\n",
            "Epoch 26/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4197 - mse: 0.4197 - val_loss: 0.4853 - val_mse: 0.4853\n",
            "Epoch 27/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4218 - mse: 0.4218 - val_loss: 0.5174 - val_mse: 0.5174\n",
            "Epoch 28/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.4075 - mse: 0.4075 - val_loss: 0.5716 - val_mse: 0.5716\n",
            "Epoch 29/100\n",
            "149/149 [==============================] - 2s 10ms/step - loss: 0.4048 - mse: 0.4048 - val_loss: 0.5079 - val_mse: 0.5079\n",
            "Epoch 30/100\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.3942 - mse: 0.3942 - val_loss: 0.5480 - val_mse: 0.5480\n",
            "Epoch 31/100\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.3915 - mse: 0.3915 - val_loss: 0.5071 - val_mse: 0.5071\n",
            "Epoch 32/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3805 - mse: 0.3805 - val_loss: 0.4886 - val_mse: 0.4886\n",
            "Epoch 33/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3862 - mse: 0.3862 - val_loss: 0.5377 - val_mse: 0.5377\n",
            "Epoch 34/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.5900 - val_mse: 0.5900\n",
            "Epoch 35/100\n",
            "149/149 [==============================] - 2s 10ms/step - loss: 0.3793 - mse: 0.3793 - val_loss: 0.5268 - val_mse: 0.5268\n",
            "Epoch 36/100\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.3709 - mse: 0.3709 - val_loss: 0.5387 - val_mse: 0.5387\n",
            "Epoch 37/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3675 - mse: 0.3675 - val_loss: 0.5127 - val_mse: 0.5127\n",
            "Epoch 38/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3718 - mse: 0.3718 - val_loss: 0.6272 - val_mse: 0.6272\n",
            "Epoch 39/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3566 - mse: 0.3566 - val_loss: 0.6559 - val_mse: 0.6559\n",
            "Epoch 40/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3568 - mse: 0.3568 - val_loss: 0.5987 - val_mse: 0.5987\n",
            "Epoch 41/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3503 - mse: 0.3503 - val_loss: 0.6117 - val_mse: 0.6117\n",
            "Epoch 42/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3548 - mse: 0.3548 - val_loss: 0.5685 - val_mse: 0.5685\n",
            "Epoch 43/100\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3508 - mse: 0.3508 - val_loss: 0.5938 - val_mse: 0.5938\n",
            "Epoch 44/100\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.3395 - mse: 0.3395 - val_loss: 0.5853 - val_mse: 0.5853\n",
            "Epoch 45/100\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.3353 - mse: 0.3353 - val_loss: 0.5623 - val_mse: 0.5623\n",
            "Epoch 46/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3321 - mse: 0.3321 - val_loss: 0.6164 - val_mse: 0.6164\n",
            "Epoch 47/100\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3333 - mse: 0.3333 - val_loss: 0.6625 - val_mse: 0.6625\n",
            "Epoch 48/100\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.3291 - mse: 0.3291 - val_loss: 0.5974 - val_mse: 0.5974\n",
            "Epoch 49/100\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.3325 - mse: 0.3325 - val_loss: 0.6153 - val_mse: 0.6153\n",
            "Epoch 50/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3227 - mse: 0.3227 - val_loss: 0.5713 - val_mse: 0.5713\n",
            "Epoch 51/100\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.3094 - mse: 0.3094 - val_loss: 0.6429 - val_mse: 0.6429\n",
            "Epoch 52/100\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.3219 - mse: 0.3219 - val_loss: 0.6140 - val_mse: 0.6140\n",
            "Epoch 53/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3173 - mse: 0.3173 - val_loss: 0.5695 - val_mse: 0.5695\n",
            "Epoch 54/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3215 - mse: 0.3215 - val_loss: 0.5849 - val_mse: 0.5849\n",
            "Epoch 55/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3062 - mse: 0.3062 - val_loss: 0.6411 - val_mse: 0.6411\n",
            "Epoch 56/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3011 - mse: 0.3011 - val_loss: 0.6042 - val_mse: 0.6042\n",
            "Epoch 57/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3041 - mse: 0.3041 - val_loss: 0.6500 - val_mse: 0.6500\n",
            "Epoch 58/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.3055 - mse: 0.3055 - val_loss: 0.5855 - val_mse: 0.5855\n",
            "Epoch 59/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2951 - mse: 0.2951 - val_loss: 0.6297 - val_mse: 0.6297\n",
            "Epoch 60/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2941 - mse: 0.2941 - val_loss: 0.6488 - val_mse: 0.6488\n",
            "Epoch 61/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2956 - mse: 0.2956 - val_loss: 0.5865 - val_mse: 0.5865\n",
            "Epoch 62/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2945 - mse: 0.2945 - val_loss: 0.5567 - val_mse: 0.5567\n",
            "Epoch 63/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2901 - mse: 0.2901 - val_loss: 0.6391 - val_mse: 0.6391\n",
            "Epoch 64/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.3050 - mse: 0.3050 - val_loss: 0.6801 - val_mse: 0.6801\n",
            "Epoch 65/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2921 - mse: 0.2921 - val_loss: 0.6577 - val_mse: 0.6577\n",
            "Epoch 66/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2811 - mse: 0.2811 - val_loss: 0.6158 - val_mse: 0.6158\n",
            "Epoch 67/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2785 - mse: 0.2785 - val_loss: 0.6465 - val_mse: 0.6465\n",
            "Epoch 68/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2878 - mse: 0.2878 - val_loss: 0.6694 - val_mse: 0.6694\n",
            "Epoch 69/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2734 - mse: 0.2734 - val_loss: 0.5974 - val_mse: 0.5974\n",
            "Epoch 70/100\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.2784 - mse: 0.2784 - val_loss: 0.7461 - val_mse: 0.7461\n",
            "Epoch 71/100\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2694 - mse: 0.2694 - val_loss: 0.7490 - val_mse: 0.7490\n",
            "Epoch 72/100\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.2679 - mse: 0.2679 - val_loss: 0.6129 - val_mse: 0.6129\n",
            "Epoch 73/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 0.7359 - val_mse: 0.7359\n",
            "Epoch 74/100\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.2725 - mse: 0.2725 - val_loss: 0.8612 - val_mse: 0.8612\n",
            "Epoch 75/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2763 - mse: 0.2763 - val_loss: 0.6158 - val_mse: 0.6158\n",
            "Epoch 76/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.7549 - val_mse: 0.7549\n",
            "Epoch 77/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 0.7322 - val_mse: 0.7322\n",
            "Epoch 78/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2582 - mse: 0.2582 - val_loss: 0.7072 - val_mse: 0.7072\n",
            "Epoch 79/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2606 - mse: 0.2606 - val_loss: 0.6310 - val_mse: 0.6310\n",
            "Epoch 80/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 0.7820 - val_mse: 0.7820\n",
            "Epoch 81/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2537 - mse: 0.2537 - val_loss: 0.7568 - val_mse: 0.7568\n",
            "Epoch 82/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2536 - mse: 0.2536 - val_loss: 0.7228 - val_mse: 0.7228\n",
            "Epoch 83/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2491 - mse: 0.2491 - val_loss: 0.6749 - val_mse: 0.6749\n",
            "Epoch 84/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2467 - mse: 0.2467 - val_loss: 0.6891 - val_mse: 0.6891\n",
            "Epoch 85/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2513 - mse: 0.2513 - val_loss: 0.7251 - val_mse: 0.7251\n",
            "Epoch 86/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2458 - mse: 0.2458 - val_loss: 0.7129 - val_mse: 0.7129\n",
            "Epoch 87/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2438 - mse: 0.2438 - val_loss: 0.7499 - val_mse: 0.7499\n",
            "Epoch 88/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2433 - mse: 0.2433 - val_loss: 0.7400 - val_mse: 0.7400\n",
            "Epoch 89/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2452 - mse: 0.2452 - val_loss: 0.7565 - val_mse: 0.7565\n",
            "Epoch 90/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2443 - mse: 0.2443 - val_loss: 0.7517 - val_mse: 0.7517\n",
            "Epoch 91/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2355 - mse: 0.2355 - val_loss: 0.7455 - val_mse: 0.7455\n",
            "Epoch 92/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2532 - mse: 0.2532 - val_loss: 0.8598 - val_mse: 0.8598\n",
            "Epoch 93/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.8211 - val_mse: 0.8211\n",
            "Epoch 94/100\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.2461 - mse: 0.2461 - val_loss: 0.8294 - val_mse: 0.8294\n",
            "Epoch 95/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2320 - mse: 0.2320 - val_loss: 0.6936 - val_mse: 0.6936\n",
            "Epoch 96/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2295 - mse: 0.2295 - val_loss: 0.7337 - val_mse: 0.7337\n",
            "Epoch 97/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.8344 - val_mse: 0.8344\n",
            "Epoch 98/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2286 - mse: 0.2286 - val_loss: 0.8129 - val_mse: 0.8129\n",
            "Epoch 99/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.8333 - val_mse: 0.8333\n",
            "Epoch 100/100\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.2236 - mse: 0.2236 - val_loss: 0.8020 - val_mse: 0.8020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8728b53790>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test of accuracy on training data \n",
        "predictions = model.predict(training_features)\n",
        "for p in range(10,15):\n",
        "   prediction = str(predictions[p,0])\n",
        "   actual = train_labels[p]\n",
        "   print(prediction, actual)"
      ],
      "metadata": {
        "id": "trNmXKaheZ-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993a8cc4-b505-4f10-d318-2b9962c63b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.82352847 0.299317082414784\n",
            "0.48318005 0.151013990079708\n",
            "0.684715 0.974245527905857\n",
            "0.6879412 0.557997957647867\n",
            "2.4197829 1.90212685959492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using model\n",
        "predictions = model.predict(testing_features)\n",
        "\n",
        "# Write a CSV file \n",
        "div_predictions=predictions.flatten()\n",
        "div_df=pd.DataFrame(data=div_predictions, columns = ['DIFF'])\n",
        "div_df['SGD']=test_SGD\n",
        "div_df.set_index('DIFF', inplace=True)\n",
        "\n",
        "div_df.to_csv('prediction.csv')\n",
        "\n",
        "div_df"
      ],
      "metadata": {
        "id": "s0JRNZJKsgkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "98fa7e88-98bc-4183-b9d8-c9490b0a289b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              SGD\n",
              "DIFF             \n",
              "1.509571  YOL031C\n",
              "0.652272  YER032W\n",
              "1.076889  YPL172C\n",
              "1.600312  YJL155C\n",
              "0.789321  YOL093W\n",
              "...           ...\n",
              "1.788472  YDL198C\n",
              "1.720836  YOR317W\n",
              "0.736998  YDR236C\n",
              "0.599973  YBL086C\n",
              "0.528800  YDL113C\n",
              "\n",
              "[698 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f9b7544-c5d1-428b-9bf9-ed018e3dcee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SGD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIFF</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.509571</th>\n",
              "      <td>YOL031C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.652272</th>\n",
              "      <td>YER032W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.076889</th>\n",
              "      <td>YPL172C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.600312</th>\n",
              "      <td>YJL155C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.789321</th>\n",
              "      <td>YOL093W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.788472</th>\n",
              "      <td>YDL198C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.720836</th>\n",
              "      <td>YOR317W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.736998</th>\n",
              "      <td>YDR236C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.599973</th>\n",
              "      <td>YBL086C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.528800</th>\n",
              "      <td>YDL113C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>698 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f9b7544-c5d1-428b-9bf9-ed018e3dcee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f9b7544-c5d1-428b-9bf9-ed018e3dcee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f9b7544-c5d1-428b-9bf9-ed018e3dcee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This box gives some stats on the predictions \n",
        "div=div_df.reset_index()\n",
        "div['DIFF'].describe()"
      ],
      "metadata": {
        "id": "roM8U8gnsL0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee2ae8-3667-4583-85dd-f6fb5b80be9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    698.000000\n",
              "mean       0.966464\n",
              "std        0.680192\n",
              "min        0.308674\n",
              "25%        0.602034\n",
              "50%        0.747374\n",
              "75%        1.027082\n",
              "max        6.707862\n",
              "Name: DIFF, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-6rNeuNkg2P",
        "outputId": "ae9c8bbe-d63e-410f-94c4-2b3474625930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2793.000000\n",
              "mean        0.924559\n",
              "std         0.734205\n",
              "min         0.000000\n",
              "25%         0.426961\n",
              "50%         0.711980\n",
              "75%         1.195470\n",
              "max         5.293015\n",
              "Name: DIFF, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}